{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory to save machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "current_dir = os.path.abspath('')\n",
    "model_dir = os.path.join(current_dir, \"data\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Fashion MNIST dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data: Data normalization.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data.\n",
    "len(test_labels)\n",
    "# 10000\n",
    "train_images.shape\n",
    "# (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#  Plot one input image.\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def train_model(train_images, train_labels):\n",
    "    # Define Keras deep-learning model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            keras.layers.Dense(128, activation=\"relu\"),\n",
    "            keras.layers.Dense(10),\n",
    "            keras.layers.Activation('softmax')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Setup the model for training:\n",
    "    # Loss function — This measures how accurate the model is during\n",
    "    #                 training. You want to minimize this function to\n",
    "    #                 \"steer\" the model in the right direction.\n",
    "    # Optimizer — This is how the model is updated based on the data it\n",
    "    #             sees and its loss function.\n",
    "    # Metrics — Used to monitor the training and testing steps.\n",
    "    #           The following example uses accuracy, the fraction of the\n",
    "    #           images that are correctly classified.\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Model training.\n",
    "    model.fit(train_images, train_labels, epochs=2)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Execute training.\n",
    "model = train_model(train_images, train_labels)\n",
    "\n",
    "# Save the model in SavedModel format, if needed.\n",
    "model.save(os.path.join(model_dir,\"MNIST_model_TF\"), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a saved model (in case the model has already been trained and stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(model_dir,\"MNIST_model_TF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "    test_images, test_labels, verbose=2\n",
    ")\n",
    "print(\"\\nTest accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a local single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_images[0:1, :, :]\n",
    "prediction = model.predict(test_image)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to TFLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to run the model in the Avato enclave it first needs\n",
    "# to be converted into a simpler format called `TFLite`,\n",
    "# also provided and maintained by Google.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model in flatbuffer format, if necessary\n",
    "with open(os.path.join(model_dir, \"MNIST.fb\"), \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a TFLite model (in case the model has already been converted and stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir, \"MNIST.fb\"), \"rb\") as f:\n",
    "    tflite_model = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avato import Client\n",
    "from avato import Secret\n",
    "from avato_tflite_dynamic import TFLITEDYNAMIC_Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to avato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model_owner_client = Client(\n",
    "    api_token=os.environ[\"MODEL_OWNER_API_TOKEN\"],\n",
    "    instance_types=[TFLITEDYNAMIC_Instance],\n",
    "    backend_host=\"api.decentriq.ch\",\n",
    "    backend_port=\"15005\",\n",
    "    use_ssl=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_user_id = os.environ[\"INFERENCE_USER_ID\"]\n",
    "model_owner_instance = model_owner_client.create_instance(\n",
    "    \"Inference Demo\",\n",
    "    TFLITEDYNAMIC_Instance.type,\n",
    "    [inference_user_id],\n",
    ")\n",
    "print(model_owner_instance.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check security guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the fatquote. This step is crucial for all security\n",
    "# guarantees.\n",
    "# It gets and validates the cryptographic proof from the enclave:\n",
    "#\n",
    "# i)   It proves it is a valid SGX enclave (by checking a certificate).\n",
    "# ii)  It compares the hash of the enclave code provided by the user to\n",
    "#      an expected value (to verify what code is running in the enclave).\n",
    "# iii) As part of the proof also a public key is transmitted that allows\n",
    "#      establishing a secure connection into the enclave (as the private\n",
    "#      key is only known to the enclave).\n",
    "#\n",
    "# As we are using a non-production environment, we whitelist debug and\n",
    "# out_of_data flags\n",
    "\n",
    "model_owner_instance.validate_fatquote(\n",
    "    expected_measurement=\"6a2c1e90d79f09b9435b57301d388af8eaefde7e0b8feef345481a2a0527cfd2\",\n",
    "    accept_debug=True,\n",
    "    accept_group_out_of_date=True,\n",
    ")\n",
    "\n",
    "print(model_owner_instance.fatquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The quote is part of the fatquote and provides a detailed fingerprint\n",
    "#  of the program and state of the remote machine. For example:\n",
    "#  * using `flags` we can detect if the CPU is running in un-trusted\n",
    "#    debug mode\n",
    "#  * using `*_snv` we can verify if all security patches have been\n",
    "#    deployed to the infrastructure\n",
    "#  * using `mrenclave` we can attest to the exact program being\n",
    "#    executed on the remote machine\n",
    "print(model_owner_instance.quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating (randomly) a public-private keypair and setting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_owner_secret = Secret()\n",
    "model_owner_instance.set_secret(model_owner_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before uploading, the model is encrypted using the enclave\n",
    "# public key extracted from the fatquote.\n",
    "# The model_owner public key also sent together with the encrypted data.\n",
    "model_owner_instance.upload_model(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a local single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_remote = model_owner_instance.predict(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the little difference due to the fact that the TFLite model\n",
    "# uses 32-bit precision, (like most models), while the local prediction\n",
    "# is done on 64-bit precision.\n",
    "print(f\"Local - Label: {prediction.argmax()} with weight: {prediction.max()}\")\n",
    "print(\n",
    "    f\"Remote - Label: {prediction_remote.argmax()} with weight: {prediction_remote.max()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup the enclave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_owner_instance.shutdown()\n",
    "model_owner_instance.delete()\n",
    "assert model_owner_instance.id not in model_owner_client.get_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
